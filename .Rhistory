z =  z - (1/1) *  gradient
z
gradient
gradient = 0
for(i in 1 : 100)
{
gradient = gradient + weights[i] * d.list$S[i,]
}
z = c(1,2,3,4,-2)
weights = diag(as.numeric(classify(d.list$S,z) != d.list$y) %*% t(-d.list$y))
gradient = 0
for(i in 1 : 100)
{
gradient = gradient + weights[i] * d.list$S[i,]
}
z =  z - (1/1) *  gradient
z
gradient
perceptrain = function(S,y)
{
#number of observations:
n = dim(S)[1]
#dimension of data
d = dim(S)[2]
#Start an initial value:
z = c(rep(1,d-1),-1)
#Set up the initial matrix of Z_History
Z_history = z
#number of iterations
k = 1
#Testing whether the cost is zero
while((t(as.numeric(classify(S,z) != y)) %*% abs(S %*% z)) != 0)
{
weights = diag(as.numeric(classify(S,z) != y) %*% t(-y))
gradient = 0
#Calculate the gradient
for(i in 1 : n)
{
gradient = gradient + weights[i] * S[i,]
}
z =  z - (1/k) *  gradient
k = k + 1
Z_history = rbind(Z_history,z)
}
return(list(z=z,Z_history = Z_history))
}
z = c(1,2,3,4,-2)
d.list = fakedata(z,100)
t.list = perceptrain(d.list$S,d.list$y)
t.list$z
t.list$Z_history
z = c(1,2,3,4,-2)
d.list = fakedata(z,100)
t.list = perceptrain(d.list$S,d.list$y)
v.list = classify(d.list$S,t.list$z)
v.list
sum(v.list = d.list$y)
sum(v.list == d.list$y)
fake.data = fakedata(z,100)
z = c(1,2,3,4,-2)
fake.data = fakedata(z,100)
train.z = perceptrain(fake.data$S,fake.data$y)
test = classify(fake.data$S,train.z$z)
sum(test == fake.data$y) == 100
perceptrain = function(S,y)
{
#number of observations:
n = dim(S)[1]
#dimension of each observation
d = dim(S)[2]
#Start an initial value:
z = c(rep(1,d-1),-1)
#Set up the initial matrix of Z_History
Z_history = z
#initial number of iterations
k = 1
while((t(as.numeric(classify(S,z) != y)) %*% abs(S %*% z)) != 0)#Testing whether the cost is zero
{
weights = diag(as.numeric(classify(S,z) != y) %*% t(-y))
gradient = 0
#Calculate the gradient
for(i in 1 : n)
{
gradient = gradient + weights[i] * S[i,]
}
#update the z vector
z =  z - (1/k) *  gradient
#update number of iterations
k = k + 1
#update the Z_history matrix
Z_history = rbind(Z_history,z)
}
return(list(z=z,Z_history = Z_history))
}
#Checking for the function created:
#random choice of z:
z = c(1,2,3,4,-2)
#Generate fake data
fake.data = fakedata(z,100)
#Train to get a estimation of z
train.z = perceptrain(fake.data$S,fake.data$y)
#Testing the trained classifier on the fake data
test = classify(fake.data$S,train.z$z)
#Check whether the trained classifier correctly classify its own training data
sum(test == fake.data$y) == 100
#Thus the function works fine.
z = c(4,1,-6)
train.data = fakedata(z,100)
z.esti = perceptrain(train.data)
z.esti = perceptrain(train.data$S, train.data$y)
#Generate a random three dimensional random vector z
z = c(2,1,-3)
#Generate training data set:
train.data = fakedata(z,100)
#Train for an estimation of z
z.esti = perceptrain(train.data$S, train.data$y)
test.data = fakedata(z,100)
classify(test.data$S,z.esti$z) == test.data$y
sum(classify(test.data$S,z.esti$z) == test.data$y) == 100
z = c(2,1,-3)
train.data = fakedata(z,100)
z.esti = perceptrain(train.data$S, train.data$y)
#Generate a random three dimensional random vector z
z = c(2,1,-3)
#Generate training data set:
train.data = fakedata(z,100)
#Train for an estimation of z
z.est = perceptrain(train.data$S, train.data$y)
#Generating test set
test.data = fakedata(z,100)
#Check for performance
sum(classify(test.data$S,z.est$z) == test.data$y) == 100
z.est$z
z = c(2,1,-3)
train.data = fakedata(z,100)
z.est = perceptrain(train.data$S, train.data$y)
z.est$z
z
test.data = fakedata(z,100)
sum(classify(test.data$S,z.est$z) == test.data$y) == 100
z = c(1,2,3,4,-2)
fake.data = fakedata(z,100)
train.z = perceptrain(fake.data$S,fake.data$y)
train.z$z
test = classify(fake.data$S,train.z$z)
sum(test == fake.data$y) == 100
z = c(2,1,-3)
train.data = fakedata(z,100)
z.est = perceptrain(train.data$S, train.data$y)
z.est$z
test.data = fakedata(z,100)
sum(classify(test.data$S,z.est$z) == test.data$y) == 100
train.data
z = c(1,1,-1)
train.data = fakedata(z,100)
z.est = perceptrain(train.data$S, train.data$y)
#random choice of z:
z = c(1,2,3,4,-2)
#Generate fake data
fake.data = fakedata(z,100)
#Train to get a estimation of z
train.z = perceptrain(fake.data$S,fake.data$y)
#Testing the trained classifier on the fake data
test = classify(fake.data$S,train.z$z)
#Check whether the trained classifier correctly classify its own training data
sum(test == fake.data$y) == 100
#Thus the function works fine.
train.z$z
#random choice of z:
z = c(1,1,-2)
#Generate fake data
fake.data = fakedata(z,100)
#Train to get a estimation of z
train.z = perceptrain(fake.data$S,fake.data$y)
#Testing the trained classifier on the fake data
test = classify(fake.data$S,train.z$z)
#Check whether the trained classifier correctly classify its own training data
sum(test == fake.data$y) == 100
#Thus the function works fine.
train.z$z
#random choice of z:
z = c(1,1,1,1,1,1,1,1,-2)
#Generate fake data
fake.data = fakedata(z,100)
#Train to get a estimation of z
train.z = perceptrain(fake.data$S,fake.data$y)
#Testing the trained classifier on the fake data
test = classify(fake.data$S,train.z$z)
#Check whether the trained classifier correctly classify its own training data
sum(test == fake.data$y) == 100
#Thus the function works fine.
train.z$z
train.z$z/z
#Generate a random three dimensional random vector z
z = c(1,1,-3)
#Generate training data set:
train.data = fakedata(z,100)
#Train for an estimation of z
z.esti = perceptrain(train.data$S, train.data$y)
#Generating test set
test.data = fakedata(z,100)
#Check for performance
mean(as.numeric(classify(test.data$S,z.esti$z)))
#Generate a random three dimensional random vector z
z = c(1,1,-3)
#Generate training data set:
train.data = fakedata(z,100)
#Train for an estimation of z
z.esti = perceptrain(train.data$S, train.data$y)
#Generating test set
test.data = fakedata(z,100)
#Check for performance
mean(as.numeric(classify(test.data$S,z.esti$z) != test.data$y))
z.esti$z
z.esti$z/z
#Generate a random three dimensional random vector z
z = c(1,1,-3)
#Generate training data set:
train.data = fakedata(z,100)
#Train for an estimation of z
z.esti = perceptrain(train.data$S, train.data$y)
#Generating test set
test.data = fakedata(z,100)
#Check for performance
mean(as.numeric(classify(test.data$S,z.esti$z) != test.data$y))
#It performs relatively well.
z.esti
z.esti$z
#Generate a random three dimensional random vector z
z = c(1,1,-3)
#Generate training data set:
train.data = fakedata(z,100)
#Train for an estimation of z
z.est = perceptrain(train.data$S, train.data$y)
#Generating test set
test.data = fakedata(z,100)
#Check for performance
mean(as.numeric(classify(test.data$S,z.est$z) != test.data$y))
#It performs relatively well.
z.est$z
#Generate a random three dimensional random vector z
z = c(1,1,-3)
#Generate training data set:
train.data = fakedata(z,100)
#Train for an estimation of z
z.est = perceptrain(train.data$S, train.data$y)
#Generating test set
test.data = fakedata(z,100)
#Check for performance
mean(as.numeric(classify(test.data$S,z.est$z) != test.data$y))
#It performs relatively well.
z.est$z
#Generate a random three dimensional random vector z
z = c(1,1,-3)
#Generate training data set:
train.data = fakedata(z,100)
#Train for an estimation of z
z.est = perceptrain(train.data$S, train.data$y)
#Generating test set
test.data = fakedata(z,100)
#Check for performance
mean(as.numeric(classify(test.data$S,z.est$z) != test.data$y))
#The mean error rate is extremely low, thus it performs relatively well.
test.data$S
plot.test$class = test.data$y
plot.test = test.data$S
plot.test$class = test.data$y
plot.test
mode(test.data$y)
test.data$y
plot.test = test.data$S
mode(plot.test)
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
library(ggplot2)
library(ggplot2)
#Creating the test data set and classifier hyperplane:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(x=plot.test$x,y=plot.test$y,col = level(plot.test$class))
library(ggplot2)
#Creating the test data set and classifier hyperplane:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(x=plot.test$x,y=plot.test$y,col = levels(plot.test$class))
library(ggplot2)
#Creating the test data set and classifier hyperplane:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(x=plot.test$x,y=plot.test$y,col = plot.test$class)
library(ggplot2)
#Creating the test data set and classifier hyperplane:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(x=plot.test$x,y=plot.test$y,col = plot.test$class+1)
library(ggplot2)
#Creating the test data set and classifier hyperplane:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(x=plot.test$x,y=plot.test$y,colour = plot.test$class)
library(ggplot2)
#Creating the test data set and classifier hyperplane:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(mapping =aes(x=plot.test$x,y=plot.test$y,colour = plot.test$class))
plot.test$class
library(ggplot2)
#Creating the test data set and classifier hyperplane:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(mapping =aes(x=plot.test$x,y=plot.test$y),colour = plot.test$class)
library(ggplot2)
#Creating the test data set and classifier hyperplane:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(mapping =aes(x=plot.test$x,y=plot.test$y,col = plot.test$class))
library(ggplot2)
#Creating the test data set and classifier hyperplane:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(mapping =aes(x=plot.test$x,y=plot.test$y,col = as.character(plot.test$class)))
library(ggplot2)
#Creating the test data set and classifier hyperplane:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(mapping =aes(x=plot.test$x,y=plot.test$y,col = as.character(plot.test$class)))+
labs(title = "Plot of test data set", xlab = "X", ylab = "Y")
library(ggplot2)
#Creating the test data set and classifier hyperplane:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(mapping =aes(x=plot.test$x,y=plot.test$y,col = as.character(plot.test$class)))+
labs(title = "Plot of test data set", x = "X", y = "Y")
library(ggplot2)
#Creating the test data set and classifier hyperplane:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(mapping =aes(x=plot.test$x,y=plot.test$y,col = as.character(plot.test$class)))+
labs(title = "Plot of test data set", x = "X", y = "Y")+
theme(legend.title = "Class")
library(ggplot2)
#Creating the test data set and classifier hyperplane:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(mapping =aes(x=plot.test$x,y=plot.test$y,col = as.character(plot.test$class)))+
labs(title = "Plot of test data set", x = "X", y = "Y")+
scale_fill_discrete(name="Class")
library(ggplot2)
#Creating the test data set and classifier hyperplane:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(mapping =aes(x=plot.test$x,y=plot.test$y,col = as.character(plot.test$class)))+
labs(title = "Plot of test data set", x = "X", y = "Y")+
scale_fill_discrete(name="Class")
library(ggplot2)
#Creating the test data set and classifier hyperplane:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(mapping =aes(x=plot.test$x,y=plot.test$y,col = as.character(plot.test$class)))+
labs(title = "Plot of test data set", x = "X", y = "Y")+
scale_color_discrete(name="Class")
library(ggplot2)
#Creating the test data set and classifier hyperplane:
#Creating the data set:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(mapping =aes(x=plot.test$x,y=plot.test$y,col = as.character(plot.test$class)))+
labs(title = "Plot of test data set", x = "X", y = "Y")+
scale_color_discrete(name="Class")+
geom_abline(slope = -1, intercpet = 0)
library(ggplot2)
#Creating the test data set and classifier hyperplane:
#Creating the data set:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(mapping =aes(x=plot.test$x,y=plot.test$y,col = as.character(plot.test$class)))+
labs(title = "Plot of test data set", x = "X", y = "Y")+
scale_color_discrete(name="Class")+
geom_abline(slope = -1, intercpet = 3)
#Generate a random three dimensional random vector z
z = c(1,1,-3)
#Generate training data set:
train.data = fakedata(z,100)
#Train for an estimation of z
z.est = perceptrain(train.data$S, train.data$y)
#Generating test set
test.data = fakedata(z,100)
#Check for performance
mean(as.numeric(classify(test.data$S,z.est$z) != test.data$y))
#The mean error rate is extremely low, thus it performs relatively well.
library(ggplot2)
#Creating the test data set and classifier hyperplane:
#Creating the data set:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(mapping =aes(x=plot.test$x,y=plot.test$y,col = as.character(plot.test$class)))+
labs(title = "Plot of test data set", x = "X", y = "Y")+
scale_color_discrete(name="Class")+
geom_abline(slope = -1, intercpet = 3)
z.est$z
library(ggplot2)
#Creating the test data set and classifier hyperplane:
#Creating the data set:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2],class=test.data$y)
ggplot(data = plot.test)+
geom_point(mapping =aes(x=plot.test$x,y=plot.test$y,col = as.character(plot.test$class)))+
labs(title = "Plot of test data set", x = "X", y = "Y")+
scale_color_discrete(name="Class")+
geom_abline(slope = -1, intercept = 3)
plot.train = data.frame(x=train.data$S[,1], y=train.data$S[,2], class = train.data$y)
plot.line = z.est$Z_history
plot.line
z.est$z
z.est$z/11.6094
0.9999687/1.1347937
plot.line = (z.est$z)/z.est$z[1]
#Generate a random three dimensional random vector z
z = c(1,1,-3)
#Generate training data set:
train.data = fakedata(z,100)
#Train for an estimation of z
z.est = perceptrain(train.data$S, train.data$y)
#Generating test set
test.data = fakedata(z,100)
#Check for performance
mean(as.numeric(classify(test.data$S,z.est$z) != test.data$y))
#The mean error rate is extremely low, thus it performs relatively well.
library(ggplot2)
#Creating the test data set and classifier hyperplane:
#Creating the data set:
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2], class=test.data$y)
plot.line = (z.est$z)/z.est$z[1]
ggplot(data = plot.test)+
geom_point(mapping = aes(x = plot.test$x, y = plot.test$y, col = as.character(plot.test$class)))+
labs(title = "Plot of test data set", x = "X", y = "Y")+
scale_color_discrete(name ="Class")+
geom_abline(slope = -(plot.line[1]/plot.line[2]), intercept = plot.line[3])
plot.line[1]
plot.line[2]
plot.line[3]
ggplot(data = plot.test)+
geom_point(mapping = aes(x = plot.test$x, y = plot.test$y, col = as.character(plot.test$class)))+
labs(title = "Plot of test data set", x = "X", y = "Y")+
scale_color_discrete(name ="Class")+
geom_abline(slope = -(plot.line[1]/plot.line[2]), intercept = -plot.line[3])
z.est$z
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2], class=test.data$y)
plot.line = (z.est$z)/ifelse(z.est[1],z.est[2],z.est[1]>z.est[2])
ggplot(data = plot.test)+
geom_point(mapping = aes(x = plot.test$x, y = plot.test$y, col = as.character(plot.test$class)))+
labs(title = "Plot of test data set", x = "X", y = "Y")+
scale_color_discrete(name ="Class")+
geom_abline(slope = -(plot.line[1]/plot.line[2]), intercept = -plot.line[3])
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2], class=test.data$y)
ggplot(data = plot.test)+
geom_point(mapping = aes(x = plot.test$x, y = plot.test$y, col = as.character(plot.test$class)))+
labs(title = "Plot of test data set", x = "X", y = "Y")+
scale_color_discrete(name ="Class")+
geom_abline(slope = -(plot.line[1]/plot.line[2]), intercept = -plot.line[3])
#Generate a random three dimensional random vector z
z = c(1,1,-3)
#Generate training data set:
train.data = fakedata(z,100)
#Train for an estimation of z
z.est = perceptrain(train.data$S, train.data$y)
#Generating test set
test.data = fakedata(z,100)
#Check for performance
mean(as.numeric(classify(test.data$S,z.est$z) != test.data$y))
#The mean error rate is extremely low, thus it performs relatively well.
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2], class=test.data$y)
plot.line = (z.est$z)/ifelse(z.est[1]>z.est[2],z.est[1],z.est[2])
plot.line = (z.est$z)/ifelse(z.est[1]>z.est[2],z.est[1],z.est[2])
z.est[1]
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2], class=test.data$y)
plot.line = (z.est$z)/ifelse(z.est$z[1]>z.est$z[2],z.est$z[1],z.est$z[2])
ggplot(data = plot.test)+
geom_point(mapping = aes(x = plot.test$x, y = plot.test$y, col = as.character(plot.test$class)))+
labs(title = "Plot of test data set", x = "X", y = "Y")+
scale_color_discrete(name ="Class")+
geom_abline(slope = -(plot.line[1]/plot.line[2]), intercept = -plot.line[3])
plot.test = data.frame(x=test.data$S[,1], y=test.data$S[,2], class=test.data$y)
plot.line = (z.est$z)/ifelse(z.est$z[1]<z.est$z[2],z.est$z[1],z.est$z[2])
ggplot(data = plot.test)+
geom_point(mapping = aes(x = plot.test$x, y = plot.test$y, col = as.character(plot.test$class)))+
labs(title = "Plot of test data set", x = "X", y = "Y")+
scale_color_discrete(name ="Class")+
geom_abline(slope = -(plot.line[1]/plot.line[2]), intercept = -plot.line[3])
plot.train = data.frame(x = train.data$S[,1], y = train.data$S[,2], class = train.data$y)
plot.line = z.est$Z_history
dim(plot.line)
plot.line
z.est$Z_history
plot.train = data.frame(x = train.data$S[,1], y = train.data$S[,2], class = train.data$y)
plot.line = z.est$Z_history
for(i in 1 : dim(plot.line)[1])
{
plot.line[i,] = plot.line[i,]/ifelse(plot.line[i,1]<plot.line[i,2],plot.line[i,1],plot.line[i,2])
}
ggplot(data = plot.train)+
geom_point(mapping = aes(x = plot.train$x, y = plot.train$y, col = as.character(plot.train$class)))+
labs(title="Plot of train data set with Trajectory", x = "X", y = "Y")+
scale_color_discrete(name = "Class")+
geom_abline(slope = -(plot.line[,1]/plot.line[,2]),intercept = -plot.line[,3])
runApp('app/Structure.bx.backup.R')
runApp('app/Structure.bx.backup.R')
runApp('app/Structure.bx.backup.R')
runApp('app/Structure - test.R')
runApp('app/Structure - test.R')
runApp('app/Structure - test.R')
setwd("D:/Columbia University/Spring2017-Applied Data Science/Project_2_Bz2290/Spr2017-proj2-grp4/data")
runApp('D:/Columbia University/Spring2017-Applied Data Science/Project_2_Bz2290/Spr2017-proj2-grp4/app/Structure - test.R')
runApp('D:/Columbia University/Spring2017-Applied Data Science/Project_2_Bz2290/Spr2017-proj2-grp4/app/Structure - test.R')
